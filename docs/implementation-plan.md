# ğŸš€ "å°è·Ÿç­" V1.0 è¯¦ç»†å®æ–½è®¡åˆ’

---

## ğŸ“‹ å¼€å‘é˜¶æ®µæ¦‚è§ˆ

æœ¬å®æ–½è®¡åˆ’å°†å¼€å‘åˆ†ä¸º **5ä¸ªé˜¶æ®µ**ï¼Œæ¯ä¸ªé˜¶æ®µéƒ½å¯ä»¥ç‹¬ç«‹éªŒè¯åŠŸèƒ½ï¼š

| é˜¶æ®µ | ç›®æ ‡ | é¢„è®¡è€—æ—¶ | éªŒè¯æ ‡å‡† |
|------|------|----------|----------|
| **é˜¶æ®µ1** | é¡¹ç›®æ­å»º + éŸ³é¢‘åŸºç¡€ | 1å¤© | èƒ½å½•éŸ³å’Œæ’­æ”¾ |
| **é˜¶æ®µ2** | å”¤é†’è¯ + VAD | 1-2å¤© | èƒ½è¯†åˆ«å”¤é†’è¯å¹¶å½•éŸ³ |
| **é˜¶æ®µ3** | STT + LLM + TTS | 2å¤© | èƒ½å®Œæˆå®Œæ•´å¯¹è¯ |
| **é˜¶æ®µ4** | æµå¼ä¼˜åŒ– | 1-2å¤© | å»¶è¿Ÿé™è‡³2ç§’å†… |
| **é˜¶æ®µ5** | è¿ç»­å¯¹è¯ + ä¼˜åŒ– | 1å¤© | æ”¯æŒè‡ªåŠ¨è¿ç»­å¯¹è¯ |

**æ€»é¢„è®¡è€—æ—¶**: 6-8å¤©

---

## ğŸ”§ é˜¶æ®µ1: é¡¹ç›®æ­å»º + éŸ³é¢‘åŸºç¡€

### ç›®æ ‡
æ­å»ºå®Œæ•´çš„é¡¹ç›®ç»“æ„ï¼Œå®ç°åŸºç¡€çš„éŸ³é¢‘å½•åˆ¶å’Œæ’­æ”¾åŠŸèƒ½ã€‚

### ä»»åŠ¡æ¸…å•

#### 1.1 åˆå§‹åŒ–é¡¹ç›®
```bash
# åˆ›å»ºé¡¹ç›®ç›®å½•
cd tui-assistant

# åˆå§‹åŒ–uvé¡¹ç›®
uv init
uv venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate

# åˆ›å»ºç›®å½•ç»“æ„
mkdir -p config core engines/{wake_word,vad,stt,llm,tts} audio utils models logs tests docs
touch config/{__init__.py,settings.py,config.yaml}
touch core/{__init__.py,assistant.py,state_machine.py,sentence_splitter.py}
touch engines/__init__.py engines/base.py
touch audio/{__init__.py,recorder.py,player.py}
touch utils/{__init__.py,logger.py,audio_utils.py}
touch main.py .env.example .gitignore
```

#### 1.2 ç¼–å†™ pyproject.toml
```toml
[project]
name = "tui-assistant"
version = "1.0.0"
description = "ç§äººè¯­éŸ³åŠ©ç†'å°è·Ÿç­'"
requires-python = ">=3.10"
dependencies = [
    "pyaudio>=0.2.14",
    "numpy>=1.24.0",
    "openwakeword>=0.5.0",
    "silero-vad>=4.0.0",
    "tencentcloud-sdk-python>=3.0.0",
    "openai>=1.12.0",
    "edge-tts>=6.1.0",
    "pyyaml>=6.0.1",
    "pydantic>=2.6.0",
    "pydantic-settings>=2.1.0",
    "loguru>=0.7.2",
    "aiofiles>=23.2.0",
]

[project.optional-dependencies]
dev = [
    "pytest>=8.0.0",
    "pytest-asyncio>=0.23.0",
    "ruff>=0.2.0",
]
```

#### 1.3 å®‰è£…ä¾èµ–
```bash
uv pip install -e .
uv pip install -e ".[dev]"
```

#### 1.4 å®ç°åŸºç¡€éŸ³é¢‘æ¨¡å—

**audio/recorder.py** - éŸ³é¢‘å½•åˆ¶å™¨
```python
import pyaudio
import numpy as np
from loguru import logger

class AudioRecorder:
    """éŸ³é¢‘å½•åˆ¶å™¨"""

    def __init__(self, sample_rate=16000, chunk_size=1024, channels=1):
        self.sample_rate = sample_rate
        self.chunk_size = chunk_size
        self.channels = channels
        self.audio = pyaudio.PyAudio()
        self.stream = None

    def start(self, device_index=None):
        """å¼€å§‹å½•éŸ³æµ"""
        self.stream = self.audio.open(
            format=pyaudio.paInt16,
            channels=self.channels,
            rate=self.sample_rate,
            input=True,
            input_device_index=device_index,
            frames_per_buffer=self.chunk_size
        )
        logger.info(f"å½•éŸ³æµå·²å¯åŠ¨: {self.sample_rate}Hz")

    def read_chunk(self) -> np.ndarray:
        """è¯»å–ä¸€ä¸ªéŸ³é¢‘å—"""
        data = self.stream.read(self.chunk_size, exception_on_overflow=False)
        return np.frombuffer(data, dtype=np.int16)

    def stop(self):
        """åœæ­¢å½•éŸ³"""
        if self.stream:
            self.stream.stop_stream()
            self.stream.close()
        logger.info("å½•éŸ³æµå·²åœæ­¢")

    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        self.stop()
        self.audio.terminate()
```

**audio/player.py** - éŸ³é¢‘æ’­æ”¾å™¨
```python
import pyaudio
import asyncio
from loguru import logger

class AudioPlayer:
    """éŸ³é¢‘æ’­æ”¾å™¨"""

    def __init__(self, sample_rate=16000):
        self.sample_rate = sample_rate
        self.audio = pyaudio.PyAudio()
        self.stream = None

    def start(self, device_index=None):
        """å¯åŠ¨æ’­æ”¾æµ"""
        self.stream = self.audio.open(
            format=pyaudio.paInt16,
            channels=1,
            rate=self.sample_rate,
            output=True,
            output_device_index=device_index
        )
        logger.info(f"æ’­æ”¾æµå·²å¯åŠ¨: {self.sample_rate}Hz")

    async def play_audio(self, audio_data: bytes):
        """å¼‚æ­¥æ’­æ”¾éŸ³é¢‘"""
        if not self.stream:
            raise RuntimeError("æ’­æ”¾æµæœªå¯åŠ¨")

        # åˆ†å—æ’­æ”¾é¿å…é˜»å¡
        chunk_size = 1024
        for i in range(0, len(audio_data), chunk_size):
            chunk = audio_data[i:i+chunk_size]
            self.stream.write(chunk)
            await asyncio.sleep(0)  # è®©å‡ºæ§åˆ¶æƒ

        logger.debug(f"æ’­æ”¾å®Œæˆ: {len(audio_data)} bytes")

    def stop(self):
        """åœæ­¢æ’­æ”¾"""
        if self.stream:
            self.stream.stop_stream()
            self.stream.close()
        logger.info("æ’­æ”¾æµå·²åœæ­¢")

    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        self.stop()
        self.audio.terminate()
```

#### 1.5 ç¼–å†™æµ‹è¯•ä»£ç 

**tests/test_audio.py**
```python
import asyncio
import pytest
from audio.recorder import AudioRecorder
from audio.player import AudioPlayer

@pytest.mark.asyncio
async def test_record_and_play():
    """æµ‹è¯•å½•éŸ³å’Œæ’­æ”¾"""
    recorder = AudioRecorder()
    player = AudioPlayer()

    try:
        # å½•éŸ³3ç§’
        recorder.start()
        chunks = []
        for _ in range(int(3 * 16000 / 1024)):
            chunk = recorder.read_chunk()
            chunks.append(chunk.tobytes())
        recorder.stop()

        # æ’­æ”¾å½•éŸ³
        player.start()
        audio_data = b''.join(chunks)
        await player.play_audio(audio_data)
        player.stop()

        assert len(audio_data) > 0

    finally:
        recorder.cleanup()
        player.cleanup()
```

### éªŒè¯æ ‡å‡†
è¿è¡Œæµ‹è¯•ï¼Œç¡®ä¿èƒ½æ­£å¸¸å½•éŸ³3ç§’å¹¶æ’­æ”¾å‡ºæ¥ï¼š
```bash
pytest tests/test_audio.py -v
```

---

## ğŸ¤ é˜¶æ®µ2: å”¤é†’è¯ + VAD

### ç›®æ ‡
å®ç°å”¤é†’è¯æ£€æµ‹å’Œè¯­éŸ³æ´»åŠ¨æ£€æµ‹ï¼Œèƒ½å¤Ÿåœ¨è¯´"å°è·Ÿç­"åè‡ªåŠ¨å¼€å§‹å½•éŸ³ï¼Œå¹¶åœ¨é™éŸ³æ—¶åœæ­¢ã€‚

### ä»»åŠ¡æ¸…å•

#### 2.1 å®ç°åŸºç¡€å¼•æ“æ¥å£

**engines/base.py**
```python
from abc import ABC, abstractmethod

class BaseEngine(ABC):
    """æ‰€æœ‰å¼•æ“çš„åŸºç±»"""

    @abstractmethod
    async def initialize(self):
        """å¼‚æ­¥åˆå§‹åŒ–"""
        pass

    @abstractmethod
    async def cleanup(self):
        """æ¸…ç†èµ„æº"""
        pass
```

#### 2.2 å®ç°å”¤é†’è¯å¼•æ“

**engines/wake_word/openwakeword_engine.py**
```python
import numpy as np
from openwakeword import Model
from engines.base import BaseEngine
from loguru import logger

class OpenWakeWordEngine(BaseEngine):
    """OpenWakeWordå”¤é†’è¯å¼•æ“"""

    def __init__(self, model_path: str, threshold: float = 0.5):
        self.model_path = model_path
        self.threshold = threshold
        self.model = None

    async def initialize(self):
        """åŠ è½½æ¨¡å‹"""
        # å¦‚æœæ²¡æœ‰è‡ªå®šä¹‰æ¨¡å‹ï¼Œä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹
        self.model = Model(wakeword_models=[self.model_path] if self.model_path else None)
        logger.info(f"å”¤é†’è¯æ¨¡å‹å·²åŠ è½½: {self.model_path or 'default'}")

    async def detect(self, audio_chunk: np.ndarray) -> bool:
        """æ£€æµ‹å”¤é†’è¯"""
        # é¢„æµ‹
        prediction = self.model.predict(audio_chunk)

        # æ£€æŸ¥æ‰€æœ‰æ¨¡å‹çš„é¢„æµ‹ç»“æœ
        for model_name, score in prediction.items():
            if score >= self.threshold:
                logger.info(f"æ£€æµ‹åˆ°å”¤é†’è¯: {model_name} (ç½®ä¿¡åº¦: {score:.2f})")
                return True
        return False

    async def cleanup(self):
        """æ¸…ç†èµ„æº"""
        self.model = None
        logger.info("å”¤é†’è¯å¼•æ“å·²æ¸…ç†")
```

#### 2.3 å®ç°VADå¼•æ“

**engines/vad/silero_vad_engine.py**
```python
import torch
import numpy as np
from io import BytesIO
from engines.base import BaseEngine
from audio.recorder import AudioRecorder
from loguru import logger
import asyncio

class SileroVADEngine(BaseEngine):
    """Silero VADå¼•æ“"""

    def __init__(self,
                 recorder: AudioRecorder,
                 silence_duration_ms: int = 500,
                 max_recording_seconds: int = 10):
        self.recorder = recorder
        self.silence_duration_ms = silence_duration_ms
        self.max_recording_seconds = max_recording_seconds
        self.model = None
        self.sample_rate = recorder.sample_rate

    async def initialize(self):
        """åŠ è½½Silero VADæ¨¡å‹"""
        self.model, utils = torch.hub.load(
            repo_or_dir='snakers4/silero-vad',
            model='silero_vad',
            force_reload=False
        )
        logger.info("Silero VADæ¨¡å‹å·²åŠ è½½")

    async def record_until_silence(self) -> bytes:
        """å½•éŸ³ç›´åˆ°æ£€æµ‹åˆ°é™éŸ³"""
        buffer = BytesIO()
        silence_chunks = 0
        max_chunks = int(self.max_recording_seconds * self.sample_rate / self.recorder.chunk_size)
        silence_threshold = int(self.silence_duration_ms / 1000 * self.sample_rate / self.recorder.chunk_size)

        logger.info("å¼€å§‹å½•éŸ³...")

        for i in range(max_chunks):
            chunk = self.recorder.read_chunk()
            buffer.write(chunk.tobytes())

            # VADæ£€æµ‹
            audio_float = chunk.astype(np.float32) / 32768.0
            audio_tensor = torch.from_numpy(audio_float)
            speech_prob = self.model(audio_tensor, self.sample_rate).item()

            # åˆ¤æ–­æ˜¯å¦ä¸ºé™éŸ³
            if speech_prob < 0.5:
                silence_chunks += 1
                if silence_chunks >= silence_threshold:
                    logger.info(f"æ£€æµ‹åˆ°{self.silence_duration_ms}msé™éŸ³ï¼Œåœæ­¢å½•éŸ³")
                    break
            else:
                silence_chunks = 0

            await asyncio.sleep(0)  # è®©å‡ºæ§åˆ¶æƒ

        audio_bytes = buffer.getvalue()
        logger.info(f"å½•éŸ³å®Œæˆ: {len(audio_bytes)} bytes")
        return audio_bytes

    async def listen_with_timeout(self, timeout: float = 3.0) -> bool:
        """è¿ç»­å¯¹è¯çª—å£ï¼štimeoutç§’å†…æ˜¯å¦æ£€æµ‹åˆ°äººå£°"""
        start_time = asyncio.get_event_loop().time()
        chunk_count = 0

        while (asyncio.get_event_loop().time() - start_time) < timeout:
            chunk = self.recorder.read_chunk()

            # VADæ£€æµ‹
            audio_float = chunk.astype(np.float32) / 32768.0
            audio_tensor = torch.from_numpy(audio_float)
            speech_prob = self.model(audio_tensor, self.sample_rate).item()

            if speech_prob >= 0.5:
                logger.info("è¿ç»­å¯¹è¯çª—å£æ£€æµ‹åˆ°äººå£°")
                return True

            await asyncio.sleep(0)

        logger.info("è¿ç»­å¯¹è¯çª—å£è¶…æ—¶ï¼Œæœªæ£€æµ‹åˆ°äººå£°")
        return False

    async def cleanup(self):
        """æ¸…ç†èµ„æº"""
        self.model = None
        logger.info("VADå¼•æ“å·²æ¸…ç†")
```

#### 2.4 ç¼–å†™çŠ¶æ€æœº

**core/state_machine.py**
```python
from enum import Enum, auto

class AssistantState(Enum):
    """åŠ©ç†çŠ¶æ€æšä¸¾"""
    IDLE = auto()           # å¾…æœºæ€
    LISTENING = auto()      # ç›‘å¬æ€ï¼ˆå½•éŸ³ä¸­ï¼‰
    PROCESSING = auto()     # å¤„ç†æ€ï¼ˆSTT+LLM+TTSï¼‰
    SPEAKING = auto()       # æ’­æ”¾æ€
    CONTINUOUS = auto()     # è¿ç»­å¯¹è¯çª—å£
```

### éªŒè¯æ ‡å‡†
ç¼–å†™æµ‹è¯•ç¨‹åºéªŒè¯å”¤é†’è¯å’ŒVADï¼š
```python
# tests/test_wake_vad.py
import asyncio
from audio.recorder import AudioRecorder
from engines.wake_word.openwakeword_engine import OpenWakeWordEngine
from engines.vad.silero_vad_engine import SileroVADEngine

async def test_wake_and_record():
    recorder = AudioRecorder()
    wake_engine = OpenWakeWordEngine(model_path=None, threshold=0.5)
    vad_engine = SileroVADEngine(recorder)

    await wake_engine.initialize()
    await vad_engine.initialize()

    recorder.start()

    print("ç­‰å¾…å”¤é†’è¯...")
    while True:
        chunk = recorder.read_chunk()
        if await wake_engine.detect(chunk):
            print("æ£€æµ‹åˆ°å”¤é†’è¯ï¼å¼€å§‹å½•éŸ³...")
            audio_data = await vad_engine.record_until_silence()
            print(f"å½•éŸ³å®Œæˆ: {len(audio_data)} bytes")
            break
        await asyncio.sleep(0)

    recorder.cleanup()
    await wake_engine.cleanup()
    await vad_engine.cleanup()

if __name__ == "__main__":
    asyncio.run(test_wake_and_record())
```

---

## ğŸ”„ é˜¶æ®µ3: STT + LLM + TTS å®Œæ•´å¯¹è¯

### ç›®æ ‡
å®ç°å®Œæ•´çš„å¯¹è¯æµç¨‹ï¼šè¯­éŸ³â†’æ–‡å­—â†’å¤§æ¨¡å‹â†’è¯­éŸ³ï¼Œèƒ½å¤Ÿå®Œæˆä¸€è½®å¯¹è¯ã€‚

### ä»»åŠ¡æ¸…å•

#### 3.1 å®ç°é…ç½®ç®¡ç†

**config/config.yaml**
```yaml
system:
  name: "å°è·Ÿç­"
  log_level: "INFO"

wake_word:
  engine: "openwakeword"
  model_path: null
  threshold: 0.5

vad:
  silence_duration_ms: 500
  max_recording_seconds: 10
  continuous_window_seconds: 3

stt:
  app_id: "${TENCENT_APP_ID}"
  secret_id: "${TENCENT_SECRET_ID}"
  secret_key: "${TENCENT_SECRET_KEY}"
  region: "ap-guangzhou"

llm:
  api_base: "https://api.deepseek.com/v1"
  api_key: "${DEEPSEEK_API_KEY}"
  model: "deepseek-chat"
  temperature: 0.7
  max_tokens: 500
  stream: true
  system_prompt: |
    ä½ æ˜¯"å°è·Ÿç­"ï¼Œè…¿å“¥çš„ç§äººæ™ºèƒ½åŠ©ç†ã€‚
    ä½ çš„æ€§æ ¼ï¼šèªæ˜ã€é«˜æ•ˆã€ç•¥å¸¦å¹½é»˜ã€‚
    å›ç­”è¦æ±‚ï¼šç®€æ´æ˜äº†ï¼Œå£è¯­åŒ–ï¼Œæ¯å¥è¯æ§åˆ¶åœ¨30å­—ä»¥å†…ã€‚

tts:
  voice: "zh-CN-YunxiNeural"
  rate: "+0%"
```

**config/settings.py**
```python
from pydantic import BaseModel
from pydantic_settings import BaseSettings
import yaml
import os
from pathlib import Path

class STTConfig(BaseModel):
    app_id: str
    secret_id: str
    secret_key: str
    region: str = "ap-guangzhou"

class LLMConfig(BaseModel):
    api_base: str
    api_key: str
    model: str
    temperature: float = 0.7
    max_tokens: int = 500
    stream: bool = True
    system_prompt: str

class TTSConfig(BaseModel):
    voice: str
    rate: str = "+0%"

class Settings(BaseSettings):
    stt: STTConfig
    llm: LLMConfig
    tts: TTSConfig

    class Config:
        env_file = ".env"

def load_config(config_path: str = "config/config.yaml") -> Settings:
    """åŠ è½½é…ç½®å¹¶æ›¿æ¢ç¯å¢ƒå˜é‡"""
    with open(config_path, 'r', encoding='utf-8') as f:
        config_text = f.read()

    # æ›¿æ¢ç¯å¢ƒå˜é‡
    import re
    def replace_env(match):
        var_name = match.group(1)
        return os.getenv(var_name, "")

    config_text = re.sub(r'\$\{(\w+)\}', replace_env, config_text)
    config_dict = yaml.safe_load(config_text)

    return Settings(**config_dict)
```

**.env.example**
```bash
# è…¾è®¯äº‘é…ç½®
TENCENT_APP_ID=your_app_id
TENCENT_SECRET_ID=your_secret_id
TENCENT_SECRET_KEY=your_secret_key

# DeepSeek API
DEEPSEEK_API_KEY=sk-xxxxx
```

#### 3.2 å®ç°STTå¼•æ“

**engines/stt/tencent_stt_engine.py**
```python
import base64
import json
from tencentcloud.common import credential
from tencentcloud.asr.v20190614 import asr_client, models
from engines.base import BaseEngine
from loguru import logger

class TencentSTTEngine(BaseEngine):
    """è…¾è®¯äº‘ä¸€å¥è¯è¯†åˆ«å¼•æ“"""

    def __init__(self, app_id: str, secret_id: str, secret_key: str, region: str = "ap-guangzhou"):
        self.app_id = app_id
        self.secret_id = secret_id
        self.secret_key = secret_key
        self.region = region
        self.client = None

    async def initialize(self):
        """åˆå§‹åŒ–å®¢æˆ·ç«¯"""
        cred = credential.Credential(self.secret_id, self.secret_key)
        self.client = asr_client.AsrClient(cred, self.region)
        logger.info("è…¾è®¯äº‘STTå¼•æ“å·²åˆå§‹åŒ–")

    async def transcribe(self, audio_bytes: bytes) -> str:
        """éŸ³é¢‘è½¬æ–‡å­—"""
        try:
            # æ„é€ è¯·æ±‚
            req = models.SentenceRecognitionRequest()
            req.EngSerViceType = "16k_zh"
            req.SourceType = 1
            req.VoiceFormat = "wav"
            req.DataLen = len(audio_bytes)
            req.Data = base64.b64encode(audio_bytes).decode('utf-8')

            # å‘èµ·è¯·æ±‚
            resp = self.client.SentenceRecognition(req)
            result = resp.Result

            logger.info(f"STTç»“æœ: {result}")
            return result

        except Exception as e:
            logger.error(f"STTè¯†åˆ«å¤±è´¥: {e}")
            return ""

    async def cleanup(self):
        """æ¸…ç†èµ„æº"""
        self.client = None
        logger.info("STTå¼•æ“å·²æ¸…ç†")
```

#### 3.3 å®ç°LLMå¼•æ“

**engines/llm/openai_compatible_engine.py**
```python
from openai import AsyncOpenAI
from engines.base import BaseEngine
from loguru import logger

class OpenAICompatibleEngine(BaseEngine):
    """OpenAIåè®®å…¼å®¹çš„LLMå¼•æ“"""

    def __init__(self, api_base: str, api_key: str, model: str,
                 system_prompt: str, temperature: float = 0.7):
        self.api_base = api_base
        self.api_key = api_key
        self.model = model
        self.system_prompt = system_prompt
        self.temperature = temperature
        self.client = None
        self.conversation_history = []

    async def initialize(self):
        """åˆå§‹åŒ–å®¢æˆ·ç«¯"""
        self.client = AsyncOpenAI(
            api_key=self.api_key,
            base_url=self.api_base
        )
        logger.info(f"LLMå¼•æ“å·²åˆå§‹åŒ–: {self.model}")

    async def chat_stream(self, message: str):
        """æµå¼å¯¹è¯"""
        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°å†å²
        self.conversation_history.append({"role": "user", "content": message})

        # æ„é€ æ¶ˆæ¯
        messages = [
            {"role": "system", "content": self.system_prompt},
            *self.conversation_history
        ]

        # æµå¼è¯·æ±‚
        full_response = ""
        async for chunk in await self.client.chat.completions.create(
            model=self.model,
            messages=messages,
            temperature=self.temperature,
            stream=True
        ):
            if chunk.choices[0].delta.content:
                token = chunk.choices[0].delta.content
                full_response += token
                yield token

        # æ·»åŠ åŠ©æ‰‹å›å¤åˆ°å†å²
        self.conversation_history.append({"role": "assistant", "content": full_response})
        logger.info(f"LLMå›å¤: {full_response}")

    def clear_history(self):
        """æ¸…ç©ºå¯¹è¯å†å²"""
        self.conversation_history = []

    async def cleanup(self):
        """æ¸…ç†èµ„æº"""
        await self.client.close()
        logger.info("LLMå¼•æ“å·²æ¸…ç†")
```

#### 3.4 å®ç°TTSå¼•æ“

**engines/tts/edge_tts_engine.py**
```python
import edge_tts
from engines.base import BaseEngine
from loguru import logger

class EdgeTTSEngine(BaseEngine):
    """Edge-TTSå¼•æ“"""

    def __init__(self, voice: str = "zh-CN-YunxiNeural", rate: str = "+0%"):
        self.voice = voice
        self.rate = rate

    async def initialize(self):
        """åˆå§‹åŒ–"""
        logger.info(f"Edge-TTSå¼•æ“å·²åˆå§‹åŒ–: {self.voice}")

    async def synthesize_stream(self, text: str):
        """æµå¼åˆæˆè¯­éŸ³"""
        communicate = edge_tts.Communicate(text, self.voice, rate=self.rate)
        async for chunk in communicate.stream():
            if chunk["type"] == "audio":
                yield chunk["data"]

        logger.debug(f"TTSåˆæˆå®Œæˆ: {text[:20]}...")

    async def cleanup(self):
        """æ¸…ç†èµ„æº"""
        logger.info("TTSå¼•æ“å·²æ¸…ç†")
```

### éªŒè¯æ ‡å‡†
ç¼–å†™å®Œæ•´å¯¹è¯æµ‹è¯•ï¼š
```python
# tests/test_full_conversation.py
import asyncio
from config.settings import load_config
from engines.stt.tencent_stt_engine import TencentSTTEngine
from engines.llm.openai_compatible_engine import OpenAICompatibleEngine
from engines.tts.edge_tts_engine import EdgeTTSEngine
from audio.player import AudioPlayer

async def test_conversation():
    config = load_config()

    # åˆå§‹åŒ–å¼•æ“
    stt = TencentSTTEngine(**config.stt.model_dump())
    llm = OpenAICompatibleEngine(**config.llm.model_dump())
    tts = EdgeTTSEngine(**config.tts.model_dump())
    player = AudioPlayer()

    await stt.initialize()
    await llm.initialize()
    await tts.initialize()
    player.start()

    # æµ‹è¯•å¯¹è¯
    test_audio = b"..."  # å½•éŸ³æ•°æ®

    # STT
    text = await stt.transcribe(test_audio)
    print(f"è¯†åˆ«: {text}")

    # LLM
    response = ""
    async for token in llm.chat_stream(text):
        response += token
        print(token, end="", flush=True)

    # TTS
    audio_chunks = []
    async for chunk in tts.synthesize_stream(response):
        audio_chunks.append(chunk)

    # æ’­æ”¾
    await player.play_audio(b''.join(audio_chunks))

    # æ¸…ç†
    player.cleanup()
    await stt.cleanup()
    await llm.cleanup()
    await tts.cleanup()

if __name__ == "__main__":
    asyncio.run(test_conversation())
```

---

## âš¡ é˜¶æ®µ4: æµå¼ä¼˜åŒ–

### ç›®æ ‡
å®ç°LLM â†’ TTSçš„æµå¼å¤„ç†ï¼Œå°†å»¶è¿Ÿä»3-4ç§’é™è‡³1-2ç§’ã€‚

### ä»»åŠ¡æ¸…å•

#### 4.1 å®ç°å¥å­åˆ‡åˆ†å™¨

**core/sentence_splitter.py**
```python
import re
from loguru import logger

class SentenceSplitter:
    """å¥å­åˆ‡åˆ†å™¨ - æŒ‰æ ‡ç‚¹ç¬¦å·åˆ‡åˆ†å®Œæ•´å¥å­"""

    # ä¸­æ–‡å¥å­ç»“æŸæ ‡ç‚¹
    SENTENCE_ENDINGS = ['ã€‚', 'ï¼', '?', 'ï¼›', 'â€¦']

    def __init__(self):
        self.buffer = ""

    def add_token(self, token: str) -> str | None:
        """
        æ·»åŠ tokenï¼Œå¦‚æœå½¢æˆå®Œæ•´å¥å­åˆ™è¿”å›

        Args:
            token: LLMç”Ÿæˆçš„token

        Returns:
            å®Œæ•´å¥å­æˆ–None
        """
        self.buffer += token

        # æ£€æŸ¥æ˜¯å¦åŒ…å«å¥å­ç»“æŸæ ‡ç‚¹
        for ending in self.SENTENCE_ENDINGS:
            if ending in self.buffer:
                # æ‰¾åˆ°ç¬¬ä¸€ä¸ªç»“æŸæ ‡ç‚¹çš„ä½ç½®
                idx = self.buffer.index(ending)
                sentence = self.buffer[:idx+1].strip()
                self.buffer = self.buffer[idx+1:]

                if sentence:
                    logger.debug(f"åˆ‡åˆ†å‡ºå¥å­: {sentence}")
                    return sentence

        return None

    def flush(self) -> str | None:
        """
        åˆ·æ–°ç¼“å†²åŒºï¼Œè¿”å›å‰©ä½™å†…å®¹

        Returns:
            å‰©ä½™æ–‡æœ¬æˆ–None
        """
        if self.buffer.strip():
            sentence = self.buffer.strip()
            self.buffer = ""
            logger.debug(f"åˆ·æ–°å‰©ä½™: {sentence}")
            return sentence
        return None

    def reset(self):
        """é‡ç½®ç¼“å†²åŒº"""
        self.buffer = ""
```

#### 4.2 å®ç°æµå¼å¤„ç†ä¸»é€»è¾‘

**core/assistant.py (æ ¸å¿ƒéƒ¨åˆ†)**
```python
import asyncio
from loguru import logger
from core.state_machine import AssistantState
from core.sentence_splitter import SentenceSplitter

class AssistantCore:
    """åŠ©ç†æ ¸å¿ƒæ§åˆ¶å™¨"""

    def __init__(self, config):
        self.config = config
        self.state = AssistantState.IDLE

        # å¼•æ“ï¼ˆå¾…åˆå§‹åŒ–ï¼‰
        self.wake_engine = None
        self.vad_engine = None
        self.stt_engine = None
        self.llm_engine = None
        self.tts_engine = None
        self.recorder = None
        self.player = None

        # å¥å­é˜Ÿåˆ—ï¼šLLMç”Ÿæˆçš„å¥å­ä¼ é€’ç»™TTS
        self.sentence_queue = asyncio.Queue()

    async def start(self):
        """å¯åŠ¨åŠ©ç†"""
        # åˆå§‹åŒ–æ‰€æœ‰å¼•æ“...
        logger.info("å°è·Ÿç­å·²å¯åŠ¨")

        # å¯åŠ¨ä¸¤ä¸ªå¹¶å‘ä»»åŠ¡
        await asyncio.gather(
            self._wake_and_listen_loop(),  # ç›‘å¬å’Œå¤„ç†
            self._tts_playback_loop()      # TTSæ’­æ”¾
        )

    async def _wake_and_listen_loop(self):
        """å”¤é†’å’Œç›‘å¬å¾ªç¯"""
        while True:
            if self.state == AssistantState.IDLE:
                # ç­‰å¾…å”¤é†’è¯
                chunk = self.recorder.read_chunk()
                if await self.wake_engine.detect(chunk):
                    logger.info("å”¤é†’ï¼")
                    self.state = AssistantState.LISTENING

            elif self.state == AssistantState.LISTENING:
                # VADå½•éŸ³
                audio_data = await self.vad_engine.record_until_silence()
                self.state = AssistantState.PROCESSING

                # STT
                text = await self.stt_engine.transcribe(audio_data)
                logger.info(f"ç”¨æˆ·: {text}")

                # LLMæµå¼ç”Ÿæˆ + å¥å­åˆ‡åˆ†
                await self._stream_llm_to_tts(text)

                # ç­‰å¾…TTSæ’­æ”¾å®Œæˆï¼ˆé€šè¿‡é˜Ÿåˆ—ç©ºå’ŒçŠ¶æ€åˆ¤æ–­ï¼‰
                await self.sentence_queue.join()

                # è¿›å…¥è¿ç»­å¯¹è¯çª—å£
                self.state = AssistantState.CONTINUOUS

            elif self.state == AssistantState.CONTINUOUS:
                # 3ç§’çª—å£æ£€æµ‹äººå£°
                has_speech = await self.vad_engine.listen_with_timeout(3.0)
                if has_speech:
                    # ç»§ç»­å¯¹è¯
                    self.state = AssistantState.LISTENING
                else:
                    # å›åˆ°å¾…æœº
                    self.state = AssistantState.IDLE
                    logger.info("å›åˆ°å¾…æœºçŠ¶æ€")

            await asyncio.sleep(0.01)

    async def _stream_llm_to_tts(self, user_message: str):
        """LLMæµå¼ç”Ÿæˆ + å¥å­åˆ‡åˆ† + é€å…¥TTSé˜Ÿåˆ—"""
        splitter = SentenceSplitter()

        async for token in self.llm_engine.chat_stream(user_message):
            # å°è¯•åˆ‡åˆ†å¥å­
            sentence = splitter.add_token(token)
            if sentence:
                # å°†å®Œæ•´å¥å­æ”¾å…¥é˜Ÿåˆ—
                await self.sentence_queue.put(sentence)

        # åˆ·æ–°å‰©ä½™å†…å®¹
        remaining = splitter.flush()
        if remaining:
            await self.sentence_queue.put(remaining)

        # å‘é€ç»“æŸä¿¡å·
        await self.sentence_queue.put(None)

    async def _tts_playback_loop(self):
        """TTSæ’­æ”¾å¾ªç¯"""
        while True:
            # ä»é˜Ÿåˆ—è·å–å¥å­
            sentence = await self.sentence_queue.get()

            if sentence is None:
                # ç»“æŸä¿¡å·
                self.sentence_queue.task_done()
                continue

            # TTSåˆæˆ
            audio_chunks = []
            async for chunk in self.tts_engine.synthesize_stream(sentence):
                audio_chunks.append(chunk)

            # æ’­æ”¾
            self.state = AssistantState.SPEAKING
            await self.player.play_audio(b''.join(audio_chunks))

            self.sentence_queue.task_done()
```

### éªŒè¯æ ‡å‡†
æµ‹è¯•æµå¼å¤„ç†çš„å»¶è¿Ÿï¼š
- ä»è¯´è¯ç»“æŸåˆ°ç¬¬ä¸€å¥è¯æ’­æ”¾åº” < 2ç§’
- ä½¿ç”¨ç§’è¡¨æˆ–æ—¥å¿—æ—¶é—´æˆ³éªŒè¯

---

## ğŸ” é˜¶æ®µ5: è¿ç»­å¯¹è¯ + ä¼˜åŒ–

### ç›®æ ‡
å®Œå–„è¿ç»­å¯¹è¯åŠŸèƒ½ï¼Œæ·»åŠ æ—¥å¿—ã€å¼‚å¸¸å¤„ç†å’Œä¼˜åŒ–ã€‚

### ä»»åŠ¡æ¸…å•

#### 5.1 å®Œå–„æ—¥å¿—ç³»ç»Ÿ

**utils/logger.py**
```python
from loguru import logger
import sys

def setup_logger(log_level: str = "INFO"):
    """é…ç½®æ—¥å¿—ç³»ç»Ÿ"""
    logger.remove()  # ç§»é™¤é»˜è®¤å¤„ç†å™¨

    # æ§åˆ¶å°è¾“å‡º
    logger.add(
        sys.stdout,
        level=log_level,
        format="<green>{time:HH:mm:ss}</green> | <level>{level:8}</level> | <cyan>{name}</cyan>:<cyan>{function}</cyan> - <level>{message}</level>"
    )

    # æ–‡ä»¶è¾“å‡º
    logger.add(
        "logs/assistant_{time:YYYY-MM-DD}.log",
        rotation="00:00",
        retention="7 days",
        level="DEBUG",
        format="{time:YYYY-MM-DD HH:mm:ss} | {level:8} | {name}:{function}:{line} - {message}"
    )

    logger.info("æ—¥å¿—ç³»ç»Ÿå·²åˆå§‹åŒ–")
```

#### 5.2 æ·»åŠ å¼‚å¸¸å¤„ç†

åœ¨å„ä¸ªå¼•æ“ä¸­æ·»åŠ é‡è¯•é€»è¾‘ï¼š
```python
# ç¤ºä¾‹ï¼šSTTå¼•æ“é‡è¯•
async def transcribe(self, audio_bytes: bytes, max_retries: int = 3) -> str:
    for attempt in range(max_retries):
        try:
            # ... è¯†åˆ«é€»è¾‘
            return result
        except Exception as e:
            logger.warning(f"STTè¯†åˆ«å¤±è´¥ (å°è¯• {attempt+1}/{max_retries}): {e}")
            if attempt == max_retries - 1:
                raise
            await asyncio.sleep(1)
```

#### 5.3 å®Œå–„main.py

**main.py**
```python
import asyncio
from loguru import logger
from config.settings import load_config
from utils.logger import setup_logger
from core.assistant import AssistantCore

async def main():
    """ç¨‹åºå…¥å£"""
    # åŠ è½½é…ç½®
    config = load_config()

    # è®¾ç½®æ—¥å¿—
    setup_logger(config.system.get("log_level", "INFO"))

    # åˆå§‹åŒ–åŠ©ç†
    assistant = AssistantCore(config)

    try:
        logger.info("=" * 50)
        logger.info("ğŸ  å°è·Ÿç­ç§äººåŠ©ç† V1.0")
        logger.info("=" * 50)
        await assistant.start()

    except KeyboardInterrupt:
        logger.info("\næ¥æ”¶åˆ°é€€å‡ºä¿¡å· (Ctrl+C)")

    except Exception as e:
        logger.exception(f"ç¨‹åºå¼‚å¸¸é€€å‡º: {e}")

    finally:
        await assistant.cleanup()
        logger.info("å°è·Ÿç­å·²å…³é—­ï¼Œå†è§ï¼")

if __name__ == "__main__":
    asyncio.run(main())
```

#### 5.4 ç¼–å†™README

**README.md**
```markdown
# ğŸ  å°è·Ÿç­ - ç§äººè¯­éŸ³åŠ©ç† V1.0

åŸºäºæ ‘è“æ´¾4Bçš„æ™ºèƒ½è¯­éŸ³åŠ©æ‰‹ï¼Œæ”¯æŒå”¤é†’è¯ã€æµå¼å¯¹è¯å’Œè¿ç»­å¯¹è¯ã€‚

## å¿«é€Ÿå¼€å§‹

### 1. å®‰è£…ä¾èµ–

\`\`\`bash
# å®‰è£…uvï¼ˆå¦‚æœè¿˜æ²¡æœ‰ï¼‰
curl -LsSf https://astral.sh/uv/install.sh | sh

# å…‹éš†é¡¹ç›®
git clone <your-repo>
cd tui-assistant

# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒå¹¶å®‰è£…ä¾èµ–
uv venv
source .venv/bin/activate
uv pip install -e .
\`\`\`

### 2. é…ç½®ç¯å¢ƒå˜é‡

\`\`\`bash
cp .env.example .env
# ç¼–è¾‘.envï¼Œå¡«å…¥ä½ çš„APIå¯†é’¥
\`\`\`

### 3. è¿è¡Œ

\`\`\`bash
python main.py
\`\`\`

## åŠŸèƒ½ç‰¹æ€§

- âœ… æœ¬åœ°å”¤é†’è¯æ£€æµ‹ï¼ˆopenWakeWordï¼‰
- âœ… æ™ºèƒ½VADå½•éŸ³ï¼ˆSilero VADï¼‰
- âœ… è…¾è®¯äº‘è¯­éŸ³è¯†åˆ«
- âœ… DeepSeekå¤§æ¨¡å‹å¯¹è¯
- âœ… Edge-TTSè¯­éŸ³åˆæˆ
- âœ… æµå¼å¤„ç†ï¼ˆå»¶è¿Ÿ<2ç§’ï¼‰
- âœ… è‡ªåŠ¨è¿ç»­å¯¹è¯

## é¡¹ç›®ç»“æ„

è§ `docs/implementation-plan.md`

## è®¸å¯è¯

MIT
\`\`\`

### éªŒè¯æ ‡å‡†
- å®Œæ•´è¿è¡Œä¸€æ¬¡å¯¹è¯æµç¨‹
- æµ‹è¯•è¿ç»­å¯¹è¯ï¼ˆ3ç§’å†…ç»§ç»­è¯´è¯ï¼‰
- æŸ¥çœ‹æ—¥å¿—æ–‡ä»¶æ˜¯å¦æ­£å¸¸è®°å½•

---

## ğŸ“¦ éƒ¨ç½²åˆ°æ ‘è“æ´¾

### ç³»ç»Ÿè¦æ±‚
- Raspberry Pi 4B (4GB/8GB RAM)
- Raspberry Pi OS (Debian Bullseye 64-bit)
- Python 3.10+
- ç¨³å®šWiFiè¿æ¥

### éƒ¨ç½²æ­¥éª¤

#### 1. å®‰è£…ç³»ç»Ÿä¾èµ–
\`\`\`bash
sudo apt update
sudo apt install -y python3-pip python3-venv portaudio19-dev git

# å®‰è£…uv
curl -LsSf https://astral.sh/uv/install.sh | sh
source $HOME/.cargo/env
\`\`\`

#### 2. å…‹éš†å¹¶é…ç½®é¡¹ç›®
\`\`\`bash
cd ~
git clone <your-repo> tui-assistant
cd tui-assistant

uv venv
source .venv/bin/activate
uv pip install -e .

cp .env.example .env
nano .env  # å¡«å…¥APIå¯†é’¥
\`\`\`

#### 3. é…ç½®éŸ³é¢‘è®¾å¤‡
\`\`\`bash
# æŸ¥çœ‹éŸ³é¢‘è®¾å¤‡
arecord -l   # å½•éŸ³è®¾å¤‡
aplay -l     # æ’­æ”¾è®¾å¤‡

# æµ‹è¯•éº¦å…‹é£
arecord -d 5 test.wav
aplay test.wav
\`\`\`

#### 4. è®¾ç½®å¼€æœºè‡ªå¯ï¼ˆå¯é€‰ï¼‰
\`\`\`bash
# åˆ›å»ºsystemdæœåŠ¡
sudo nano /etc/systemd/system/xiaogenban.service
\`\`\`

å†…å®¹ï¼š
\`\`\`ini
[Unit]
Description=Xiao Gen Ban Personal Assistant
After=network.target

[Service]
Type=simple
User=pi
WorkingDirectory=/home/pi/tui-assistant
Environment="PATH=/home/pi/tui-assistant/.venv/bin"
ExecStart=/home/pi/tui-assistant/.venv/bin/python main.py
Restart=on-failure

[Install]
WantedBy=multi-user.target
\`\`\`

å¯åŠ¨æœåŠ¡ï¼š
\`\`\`bash
sudo systemctl enable xiaogenban
sudo systemctl start xiaogenban
sudo systemctl status xiaogenban
\`\`\`

---

## ğŸ” å¸¸è§é—®é¢˜

### 1. PyAudioå®‰è£…å¤±è´¥
\`\`\`bash
sudo apt install portaudio19-dev
uv pip install pyaudio
\`\`\`

### 2. éº¦å…‹é£æ— æ³•å½•éŸ³
æ£€æŸ¥æƒé™ï¼š
\`\`\`bash
sudo usermod -a -G audio $USER
\`\`\`

### 3. APIè°ƒç”¨å¤±è´¥
- æ£€æŸ¥.envé…ç½®æ˜¯å¦æ­£ç¡®
- æ£€æŸ¥ç½‘ç»œè¿æ¥
- æŸ¥çœ‹logsç›®å½•ä¸‹çš„æ—¥å¿—

---

## ğŸ“ˆ åç»­ä¼˜åŒ–æ–¹å‘

1. **æ€§èƒ½ä¼˜åŒ–**
   - ä½¿ç”¨æœ¬åœ°Whisperæ›¿ä»£è…¾è®¯äº‘STT
   - éƒ¨ç½²æœ¬åœ°å°æ¨¡å‹ï¼ˆå¦‚Qwen-7Bï¼‰é™ä½å»¶è¿Ÿ

2. **åŠŸèƒ½æ‰©å±•**
   - æ·»åŠ é•¿æœŸè®°å¿†ï¼ˆVector DBï¼‰
   - å®ç°Function Callingæ§åˆ¶GPIO
   - æ”¯æŒæ‰“æ–­åŠŸèƒ½

3. **ä½“éªŒä¼˜åŒ–**
   - LEDçŠ¶æ€æŒ‡ç¤ºç¯
   - éŸ³é¢‘é™å™ªç®—æ³•
   - å¤šå”¤é†’è¯æ”¯æŒ

---

## ğŸ¯ æ€»ç»“

æœ¬å®æ–½è®¡åˆ’æä¾›äº†ä»0åˆ°1æ„å»º"å°è·Ÿç­"ç§äººåŠ©ç†çš„å®Œæ•´è·¯å¾„ï¼š

- **ç¬¬1é˜¶æ®µ**: æ­å»ºåŸºç¡€æ¡†æ¶å’ŒéŸ³é¢‘æ¨¡å—
- **ç¬¬2é˜¶æ®µ**: å®ç°å”¤é†’å’Œå½•éŸ³åŠŸèƒ½
- **ç¬¬3é˜¶æ®µ**: æ‰“é€šå®Œæ•´å¯¹è¯æµç¨‹
- **ç¬¬4é˜¶æ®µ**: ä¼˜åŒ–ä¸ºæµå¼å¤„ç†
- **ç¬¬5é˜¶æ®µ**: å®Œå–„è¿ç»­å¯¹è¯å’Œç”Ÿäº§ç‰¹æ€§

æ¯ä¸ªé˜¶æ®µéƒ½æœ‰æ˜ç¡®çš„éªŒè¯æ ‡å‡†ï¼Œå¯ä»¥é€æ­¥æ¨è¿›ã€‚é¢„è®¡6-8å¤©å®ŒæˆMVPç‰ˆæœ¬ã€‚

**ç¥ä½ å¼€å‘é¡ºåˆ©ï¼æœ‰é—®é¢˜éšæ—¶æ²Ÿé€šã€‚** ğŸš€
